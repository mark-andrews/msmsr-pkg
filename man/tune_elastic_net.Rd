% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_evaluation.R
\name{tune_elastic_net}
\alias{tune_elastic_net}
\title{Tune elastic net with alpha and lambda cross-validation}
\usage{
tune_elastic_net(x, y, alphas = seq(0, 1, by = 0.1), nfolds = 10, seed = NULL)
}
\arguments{
\item{x}{Numeric matrix of predictors (n x p).}

\item{y}{Numeric response vector (length n).}

\item{alphas}{Numeric vector of alpha values to test. Default is seq(0, 1, by = 0.1).
Alpha = 0 is ridge regression, alpha = 1 is lasso, intermediate values blend both.}

\item{nfolds}{Integer. Number of cross-validation folds. Default is 10.}

\item{seed}{Integer or NULL. Random seed for CV fold assignment. If NULL, no seed is set.}
}
\value{
An object of class \code{tune_elastic_net} containing:
\describe{
\item{best_alpha}{Optimal alpha value (minimizes CV error)}
\item{best_fit}{The \code{cv.glmnet} object for the best alpha}
\item{all_results}{Tibble with results for all alpha values tested}
\item{x}{The predictor matrix (stored for predict method)}
\item{y}{The response vector (stored for predict method)}
}
}
\description{
Performs cross-validation to find the optimal alpha (mixing parameter between
ridge and lasso) and lambda (regularization strength) for elastic net regression.
This extends standard \code{glmnet::cv.glmnet} by also tuning alpha.
}
\details{
For each alpha value, performs \code{nfolds}-fold cross-validation using
\code{glmnet::cv.glmnet}. The best alpha is chosen as the one with minimum
mean cross-validated error at lambda.min.

S3 methods are provided:
\itemize{
\item \code{print()}: Summarizes tuning results
\item \code{coef()}: Extracts coefficients at specified lambda
\item \code{predict()}: Makes predictions for new data
}
}
\examples{
# Generate example data
set.seed(123)
x <- matrix(rnorm(100 * 10), 100, 10)
y <- x[,1] + 2*x[,2] + rnorm(100)

# Tune elastic net
fit <- tune_elastic_net(x, y, seed = 42)
print(fit)
coef(fit, s = "lambda.min")

}
